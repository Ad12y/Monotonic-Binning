{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b77edb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy.stats import norm\n",
    "\n",
    "class BinningProcessor:\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "    def binning(self, feature_col, label_col, p_value_threshold, min_bin_size, min_event_rate, sort_order):\n",
    "        # Sort DataFrame based on the feature column\n",
    "        sorted_df = self.df[[feature_col, label_col]].sort_values(by=[feature_col], ascending=sort_order)\n",
    "        \n",
    "        # Extract feature and label values as lists\n",
    "        features = sorted_df[feature_col].tolist()\n",
    "        labels = sorted_df[label_col].tolist()\n",
    "        \n",
    "        # Initialize stack to store bins\n",
    "        stack = []\n",
    "\n",
    "        # Iterate through each data point\n",
    "        for i in range(len(features)):\n",
    "            # Initialize a bin\n",
    "            current_bin = [i, i, 0, labels[i]]\n",
    "            \n",
    "            # Determine whether to add the current bin to the stack\n",
    "            if len(stack) == 0 or stack[-1][-1] > labels[i]:\n",
    "                stack.append(current_bin)\n",
    "            else:\n",
    "                # Combine bins if necessary\n",
    "                previous_bin = stack.pop()\n",
    "                stack.append(self.combine_bins(previous_bin, current_bin))\n",
    "                \n",
    "                # Merge adjacent bins if needed\n",
    "                j = len(stack) - 2\n",
    "                while True:\n",
    "                    if len(stack) == 1 or j == len(stack) - 1:\n",
    "                        break\n",
    "                    elif stack[j][-1] > stack[j + 1][-1]:\n",
    "                        j += 1\n",
    "                    elif stack[j][-1] <= stack[j + 1][-1]:\n",
    "                        temp_1 = stack.pop()\n",
    "                        temp_2 = stack.pop()\n",
    "                        stack.append(self.combine_bins(temp_1, temp_2))\n",
    "                        j -= 1\n",
    "\n",
    "        # Iteratively merge bins based on p-value until threshold is met\n",
    "        while True:\n",
    "            p_value_table = []\n",
    "            for i in range(1, len(stack)):\n",
    "                p_value = self.calculate_p_value(stack[i - 1], stack[i], labels)\n",
    "                if (stack[i - 1][1] - stack[i - 1][0] + 1 < min_bin_size) or (\n",
    "                        sum(labels[stack[i - 1][0]:stack[i - 1][1] + 1]) < min_event_rate) or (\n",
    "                        stack[i][1] - stack[i][0] + 1 < min_bin_size) or (\n",
    "                        sum(labels[stack[i][0]:stack[i][1] + 1]) < min_event_rate):\n",
    "                    p_value = p_value + 1\n",
    "                p_value_table.append([p_value, stack[i]])\n",
    "            if len(p_value_table) > 0:\n",
    "                max_val = (p_value_table[0][0], 0)\n",
    "                for j in range(1, len(p_value_table)):\n",
    "                    if p_value_table[j][0] > max_val[0]:\n",
    "                        max_val = (p_value_table[j][0], j)\n",
    "                if max_val[0] > p_value_threshold:\n",
    "                    bin_1 = stack.pop(max_val[1])\n",
    "                    bin_2 = stack.pop(max_val[1])\n",
    "                    stack.insert(max_val[1], self.combine_bins(bin_1, bin_2))\n",
    "                else:\n",
    "                    break\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        # Generate bins for final output\n",
    "        bins = [features[i[1]] for i in stack]\n",
    "        \n",
    "        # Handle sorting order\n",
    "        if sort_order:\n",
    "            bins = [features[i[1]] for i in stack]\n",
    "            bins.insert(0, -np.inf)\n",
    "            bins[-1] = np.inf\n",
    "        else:\n",
    "            bins = [features[i[0]] for i in stack]\n",
    "            bins[0] = -np.inf\n",
    "            bins.insert(-1, np.inf)\n",
    "            bins.sort()\n",
    "\n",
    "        # Calculate Weight of Evidence (WoE) and Information Value (IV)\n",
    "        return self.calculate_woe_iv(sorted_df, feature_col, bins, label_col, sort_order), bins\n",
    "\n",
    "    def combine_bins(self, bin_1, bin_2):\n",
    "        # Combine two bins\n",
    "        left_2, right_2 = bin_2[0], bin_2[1]\n",
    "        left_1, right_1 = bin_1[0], bin_1[1]\n",
    "        size_1, size_2 = right_1 - left_1 + 1, right_2 - left_2 + 1\n",
    "        std_1, std_2 = bin_1[-2], bin_2[-2]\n",
    "        mean_1, mean_2 = bin_1[-1], bin_2[-1]\n",
    "        total_size = size_1 + size_2\n",
    "\n",
    "        # Calculate combined mean and standard deviation\n",
    "        if left_1 == right_1 and left_2 == right_2:\n",
    "            combined_mean = (mean_1 + mean_2) / 2\n",
    "        elif left_1 == right_1:\n",
    "            combined_mean = (mean_1 + (size_2) * mean_2) / total_size\n",
    "        elif left_2 == right_2:\n",
    "            combined_mean = ((size_1) * mean_1 + mean_2) / total_size\n",
    "        else:\n",
    "            combined_mean = ((size_1) * mean_1 + (size_2) * mean_2) / total_size\n",
    "\n",
    "        if total_size == 2:\n",
    "            combined_std = np.std([mean_1, mean_2], ddof=1)\n",
    "        else:\n",
    "            combined_std = np.sqrt((size_1 * (std_1 ** 2) + size_2 * (std_2 ** 2)) / total_size)\n",
    "\n",
    "        return [min(left_1, left_2), max(right_1, right_2), combined_std, combined_mean]\n",
    "\n",
    "    def calculate_p_value(self, bin_1, bin_2, labels):\n",
    "        # Calculate p-value between two bins\n",
    "        mean_1, mean_2 = bin_1[-1], bin_2[-1]\n",
    "        size_1 = bin_1[1] - bin_1[0] + 1\n",
    "        size_2 = bin_2[1] - bin_2[0] + 1\n",
    "        std_1 = bin_1[-2]\n",
    "        std_2 = bin_2[-2]\n",
    "        pooled_std = ((size_1) * std_1 ** 2 + (size_2) * std_2 ** 2) / (size_1 + size_2 - 2)\n",
    "        if pooled_std > 0:\n",
    "            z_value = (mean_1 - mean_2) / math.sqrt(pooled_std * (1 / size_1 + 1 / size_2))\n",
    "            p_value = 1 - norm.cdf(z_value)\n",
    "        else:\n",
    "            p_value = 2\n",
    "        return p_value\n",
    "\n",
    "    def calculate_woe_iv(self, df, feature_col, bins, target_col, sort_order):\n",
    "        # Calculate Weight of Evidence (WoE) and Information Value (IV)\n",
    "        bins_x = pd.cut(df[feature_col], bins, right=sort_order)\n",
    "        binned_df_x = pd.DataFrame(bins_x)\n",
    "        binned_df_x[target_col] = df[target_col]\n",
    "        group_df_x = binned_df_x.groupby(feature_col).agg(\n",
    "            events=(target_col, 'sum'),\n",
    "            total=(target_col, 'count')\n",
    "        ).reset_index()\n",
    "        group_df_x['non events'] = group_df_x['total'] - group_df_x['events']\n",
    "        good_sum = group_df_x['non events'].sum()\n",
    "        bad_sum = group_df_x['events'].sum()\n",
    "        group_df_x['% of events'] = group_df_x['events'] / bad_sum\n",
    "        group_df_x['% of non events'] = group_df_x['non events'] / good_sum\n",
    "        group_df_x['WoE'] = np.log(group_df_x['% of non events'] / group_df_x['% of events'])\n",
    "        WoEgood = np.where(~np.isinf(group_df_x['WoE']))[0]\n",
    "        WoEmin = np.min(group_df_x['WoE'][WoEgood])\n",
    "        WoEmax = np.max(group_df_x['WoE'][WoEgood])\n",
    "        group_df_x['IV'] = group_df_x['WoE'] * (group_df_x['% of non events'] - group_df_x['% of events'])\n",
    "        iv_val = group_df_x['IV'].sum()\n",
    "        return group_df_x, iv_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72adfdd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading a csv file\n",
    "df = pd.read_csv('C:/Users/adity/OneDrive/Documents/Monotonic Binning/train.csv')\n",
    "\n",
    "# Instantiate the BinningProcessor with your DataFrame\n",
    "processor = BinningProcessor(df)\n",
    "\n",
    "# Call the binning method\n",
    "feature_col = 'V2'  # Column to perform binning on\n",
    "label_col = 'Class'  # Label column\n",
    "p_value_threshold = 0.05  # Threshold for p-value\n",
    "min_bin_size = 10000  # Minimum bin size\n",
    "min_event_rate = 1  # Individual variable rate\n",
    "sort_order = False  # Sign of sorting (True for ascending, False for descending)\n",
    "\n",
    "result = processor.binning(feature_col, label_col, p_value_threshold, min_bin_size, min_event_rate, sort_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ff078b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((                V2  events  total  non events  % of events  % of non events  \\\n",
       "  0   [-inf, -0.313)     104  75115       75011     0.221748         0.343049   \n",
       "  1  [-0.313, 0.357)      94  59444       59350     0.200426         0.271426   \n",
       "  2   [0.357, 1.047)      84  50245       50161     0.179104         0.229402   \n",
       "  3     [1.047, inf)     187  34325       34138     0.398721         0.156124   \n",
       "  \n",
       "          WoE        IV  \n",
       "  0  0.436329  0.052927  \n",
       "  1  0.303242  0.021530  \n",
       "  2  0.247506  0.012449  \n",
       "  3 -0.937613  0.227462  ,\n",
       "  0.3143677131983261),\n",
       " [-inf, -0.313137858145954, 0.356628999499892, 1.04663468333539, inf])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
